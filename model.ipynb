{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa pretty_midi\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install miditok\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-3zEqFXm7fM",
        "outputId": "7c0a2539-2c23-416f-b4d2-b19edc72b13e"
      },
      "id": "m-3zEqFXm7fM",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Collecting mido>=1.1.16 (from pretty_midi)\n",
            "  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
            "Downloading mido-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pretty_midi\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592286 sha256=42ab8de18499ddd4a31c36cfab7bf474c10b9dd6408c0ee9ba2cde5de063d38d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/95/ac/15ceaeb2823b04d8e638fd1495357adb8d26c00ccac9d7782e\n",
            "Successfully built pretty_midi\n",
            "Installing collected packages: mido, pretty_midi\n",
            "Successfully installed mido-1.3.3 pretty_midi-0.2.10\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m124.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl (848.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.6.0+cu118\n",
            "Collecting miditok\n",
            "  Downloading miditok-3.0.5.post1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from miditok) (0.32.2)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.11/dist-packages (from miditok) (2.0.2)\n",
            "Collecting symusic>=0.5.0 (from miditok)\n",
            "  Downloading symusic-0.5.8-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from miditok) (0.21.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from miditok) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.16.4->miditok) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.16.4->miditok) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.16.4->miditok) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.16.4->miditok) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.16.4->miditok) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.16.4->miditok) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.16.4->miditok) (1.1.2)\n",
            "Collecting pySmartDL (from symusic>=0.5.0->miditok)\n",
            "  Downloading pySmartDL-1.3.4-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from symusic>=0.5.0->miditok) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.16.4->miditok) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.16.4->miditok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.16.4->miditok) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.16.4->miditok) (2025.4.26)\n",
            "Downloading miditok-3.0.5.post1-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symusic-0.5.8-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pySmartDL-1.3.4-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: pySmartDL, symusic, miditok\n",
            "Successfully installed miditok-3.0.5.post1 pySmartDL-1.3.4 symusic-0.5.8\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import librosa\n",
        "import pretty_midi\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import miditok\n",
        "from miditok import TokSequence\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "eFzQ6PKBn4Mi"
      },
      "id": "eFzQ6PKBn4Mi",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a26Z555WXCBo",
        "outputId": "41f93e36-244c-4e42-8477-6b7bc2686393"
      },
      "id": "a26Z555WXCBo",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOKENIZER_PARAMS = {\n",
        "\"pitch_range\": (20, 110),\n",
        "\"beat_res\": {(0,4):24, (4,12):12},\n",
        "\"special_tokens\": [\"PAD\", \"BOS\", \"EOS\", \"MASK\"],\n",
        "\"use_chords\": True,\n",
        "\"use_rests\": False,\n",
        "\"use_tempos\": True,\n",
        "\"use_time_signatures\": True,\n",
        "\"use_programs\": False,\n",
        "\"use_microtiming\": False,\n",
        "\"ticks_per_quarter\": 220,\n",
        "\"max_microtiming_shift\": 0.125,\n",
        "\"num_microtiming_bins\": 30,\n",
        "}\n",
        "config = miditok.TokenizerConfig(**TOKENIZER_PARAMS)\n",
        "\n",
        "tokenizer=miditok.PerTok(config)"
      ],
      "metadata": {
        "id": "JyHxZbnQyI0j"
      },
      "id": "JyHxZbnQyI0j",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "DATA_ROOT='/content/drive/My Drive/song2cover'\n",
        "PAD_TOKEN = tokenizer.pad_token_id\n",
        "EOS_TOKEN = tokenizer.special_tokens_ids[2]\n",
        "VocabSize = tokenizer.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JMxD4OPoFSQ",
        "outputId": "d0d12c2c-b151-4089-fa9a-b73aeae06e83"
      },
      "id": "8JMxD4OPoFSQ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "  xs, ys, zs, a, r = zip(*batch)\n",
        "\n",
        "\n",
        "\n",
        "  y_max_len = max([y.shape[0] for y in ys])\n",
        "\n",
        "  x_max_len = max([x.shape[2] for x in xs])\n",
        "\n",
        "  y_padded = []\n",
        "  for y in ys:\n",
        "    pad_amt = y_max_len - y.shape[0]\n",
        "    padded = F.pad(y, (0, pad_amt), value=PAD_TOKEN)\n",
        "    y_padded.append(padded)\n",
        "\n",
        "  x_padded = []\n",
        "  for x in xs:\n",
        "    pad_amt = x_max_len - x.shape[2]\n",
        "    padded = F.pad(x, (0, pad_amt), value=0)\n",
        "    x_padded.append(padded)\n",
        "\n",
        "  x_batch = torch.stack(x_padded, dim=0)\n",
        "  y_batch = torch.stack(y_padded, dim=0)\n",
        "  z_batch = torch.stack(zs, dim=0)\n",
        "  a_batch = torch.stack(a, dim=0)\n",
        "  r_batch = torch.stack(r, dim=0)\n",
        "\n",
        "  return x_batch, y_batch, z_batch, a_batch, r_batch"
      ],
      "metadata": {
        "id": "VwsDRw_rInd3"
      },
      "id": "VwsDRw_rInd3",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioMidiDataset(Dataset):\n",
        "  def __init__(self, root_dir, tokenizer, transform=None):\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "    df = pd.read_csv(os.path.join(root_dir, 'manifest.csv'))\n",
        "    self.items = df.to_dict('records')\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.items)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item = self.items[idx]\n",
        "    audio_path = os.path.join(self.root_dir, item['audio_filepath'])\n",
        "    midi_path = os.path.join(self.root_dir, item['midi_filepath'])\n",
        "    diff = torch.tensor(float(item['difficulty'])).float()\n",
        "    pos_rel = torch.tensor(float(item['pos_percent'])).float()\n",
        "    pos_abs = torch.tensor(float(item['pos_absolute']), dtype=torch.long)\n",
        "\n",
        "    y, sr = librosa.load(audio_path, sr=44100)\n",
        "    stft = librosa.stft(y, n_fft=1024, hop_length=256)\n",
        "    log_stft = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
        "    x = torch.tensor(log_stft).unsqueeze(0).float()\n",
        "\n",
        "    tokens = self.tokenizer.encode(midi_path)\n",
        "    y_tokens = torch.flatten(torch.tensor(tokens, dtype=torch.long))\n",
        "\n",
        "    eos = torch.tensor([self.tokenizer.special_tokens_ids[2]], dtype=torch.long)\n",
        "    y_tokens = torch.cat((y_tokens, eos))\n",
        "\n",
        "    sample = {\n",
        "        'x': x,\n",
        "        'y': y_tokens,\n",
        "        'diff': diff,\n",
        "        'pos_percent': pos_rel,\n",
        "        'pos_absolute': pos_abs,\n",
        "    }\n",
        "\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "\n",
        "    return x, y_tokens, diff, pos_abs, pos_rel"
      ],
      "metadata": {
        "id": "6t5cAftuoc8z"
      },
      "id": "6t5cAftuoc8z",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = AudioMidiDataset(DATA_ROOT, tokenizer)\n",
        "\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ],
      "metadata": {
        "id": "SR4dHBmcLfom"
      },
      "id": "SR4dHBmcLfom",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioEncoder(nn.Module):\n",
        "  def __init__(self, d_model=512):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(1, 64, kernel_size=3, stride=(2,2), padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64, 128, kernel_size=3, stride=(2,2), padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128, d_model, kernel_size=3, stride=(2,2), padding=1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.project = nn.Linear(in_features=d_model * 65, out_features=d_model)\n",
        "    self.pos_enc = nn.Embedding(num_embeddings=1500, embedding_dim=d_model)\n",
        "\n",
        "    enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=8, dim_feedforward=d_model * 4)\n",
        "    self.encoder = nn.TransformerEncoder(enc_layer, num_layers=3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    z = self.conv(x)\n",
        "\n",
        "    B, D, F_enc, T_enc = z.shape\n",
        "\n",
        "    enc_in = z.permute(0, 3, 1, 2).reshape(B, T_enc, D * F_enc)\n",
        "    enc_proj = self.project(enc_in)\n",
        "\n",
        "    positions = torch.arange(T_enc, device=x.device).unsqueeze(0)\n",
        "    enc_pos = enc_proj + self.pos_enc(positions)\n",
        "\n",
        "    enc_in_tp = enc_pos.permute(1,0,2)\n",
        "    enc_out_tp = self.encoder(enc_in_tp)\n",
        "\n",
        "    enc_out = enc_out_tp.permute(1,0,2)\n",
        "\n",
        "    return enc_out\n",
        "\n",
        "class TokenDecoder(nn.Module):\n",
        "  def __init__(self, vocab_size, d_model=512, max_len=1500, max_measures=200,):\n",
        "    super().__init__()\n",
        "\n",
        "\n",
        "    self.d_model = d_model\n",
        "\n",
        "    self.token_emb = nn.Embedding(num_embeddings=vocab_size, embedding_dim=d_model)\n",
        "    self.pos_emb = nn.Embedding(num_embeddings=max_len, embedding_dim=d_model)\n",
        "    self.measure_emb = nn.Embedding(num_embeddings=max_measures, embedding_dim=d_model)\n",
        "    self.diff_proj = nn.Sequential(\n",
        "        nn.Linear(in_features=1, out_features=d_model),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(d_model, d_model)\n",
        "    )\n",
        "\n",
        "    self.rel_proj = nn.Sequential(\n",
        "        nn.Linear(in_features=1, out_features=d_model),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(d_model, d_model)\n",
        "    )\n",
        "\n",
        "    dec_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=8, dim_feedforward=d_model * 4)\n",
        "    self.decoder = nn.TransformerDecoder(dec_layer, num_layers=3)\n",
        "\n",
        "    self.output_fc = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "  def forward(self, y_input, memory, diff, pos_abs, pos_rel):\n",
        "    B, T_tgt = y_input.shape\n",
        "\n",
        "    tok_embed = self.token_emb(y_input)\n",
        "\n",
        "    pos = torch.arange(T_tgt, device = y_input.device).unsqueeze(0)\n",
        "    pos_embed = self.pos_emb(pos)\n",
        "\n",
        "    measure_emb = self.measure_emb(pos_abs)\n",
        "    measure_b = measure_emb.unsqueeze(1).expand(-1, T_tgt, -1)\n",
        "\n",
        "    diff = diff.unsqueeze(-1)\n",
        "    diff_emb = self.diff_proj(diff)\n",
        "    diff_b = diff_emb.unsqueeze(1).expand(-1, T_tgt, -1)\n",
        "\n",
        "    rel = pos_rel.unsqueeze(-1)\n",
        "    rel_emb = self.rel_proj(rel)\n",
        "    rel_b = rel_emb.unsqueeze(1).expand(-1, T_tgt, -1)\n",
        "\n",
        "    tgt = tok_embed + pos_embed + measure_b + diff_b + rel_b\n",
        "\n",
        "    tgt_mask = nn.Transformer.generate_square_subsequent_mask(T_tgt).to(y_input.device)\n",
        "\n",
        "    tgt2 = tgt.permute(1,0,2)\n",
        "    mem2 = memory.permute(1,0,2)\n",
        "\n",
        "    dec_out2 = self.decoder(tgt2, mem2, tgt_mask=tgt_mask)\n",
        "\n",
        "    dec_out = dec_out2.permute(1,0,2)\n",
        "\n",
        "    logits = self.output_fc(dec_out)\n",
        "\n",
        "    return logits\n",
        "\n",
        "\n",
        "class Audio2Midi(nn.Module):\n",
        "  def __init__(self, vocab_size, d_model=512, max_tok_len=1500):\n",
        "    super().__init__()\n",
        "    self.encoder = AudioEncoder(d_model=d_model)\n",
        "    self.decoder = TokenDecoder(vocab_size, d_model=d_model, max_len=max_tok_len)\n",
        "\n",
        "  def forward(self, x_audio, y_input, diff, pos_abs, pos_rel):\n",
        "    memory = self.encoder(x_audio)\n",
        "    logits = self.decoder(y_input, memory, diff, pos_abs, pos_rel)\n",
        "\n",
        "    return logits\n",
        "\n"
      ],
      "metadata": {
        "id": "EW31ncxMOsfZ"
      },
      "id": "EW31ncxMOsfZ",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add `%load_ext cudf.pandas` before importing pandas to speed up operations using GPU"
      ],
      "metadata": {
        "id": "SlH-gSFjs2Uc"
      },
      "id": "SlH-gSFjs2Uc"
    },
    {
      "cell_type": "code",
      "source": [
        "model = Audio2Midi(vocab_size=VocabSize, d_model=512, max_tok_len=1500).to(device)\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "\n",
        "  batch_iterator = tqdm(loader, desc=f\"Epoch {epoch:02d}\", leave=False, bar_format='{l_bar}{bar} | {percentage:3.0f}%')\n",
        "\n",
        "  for x_batch, y_batch, diff_batch, abs_batch, rel_batch in batch_iterator:\n",
        "      x_batch = x_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "      diff_batch = diff_batch.to(device)\n",
        "      abs_batch = abs_batch.to(device)\n",
        "      rel_batch = rel_batch.to(device)\n",
        "\n",
        "      y_input  = y_batch[:, :-1]\n",
        "      y_target = y_batch[:, 1:]\n",
        "\n",
        "      optim.zero_grad()\n",
        "\n",
        "      with torch.cuda.amp.autocast():\n",
        "        logits = model(x_batch, y_input, diff_batch, abs_batch, rel_batch)\n",
        "\n",
        "        B, Tm, V = logits.shape\n",
        "        loss = criterion(\n",
        "            logits.reshape(-1, V),\n",
        "            y_target.reshape(-1),\n",
        "            ignore_index=PAD_TOKEN\n",
        "        )\n",
        "\n",
        "      scaler.scale(loss).backward()\n",
        "      scaler.step(optim)\n",
        "      scaler.update()\n",
        "\n",
        "      total_loss += loss.item()\n",
        "      batch_iterator.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "  avg_loss = total_loss / len(loader)\n",
        "  print(f\"Epoch {epoch:02d} — Loss {avg_loss:.4f}\")\n",
        "\n",
        "torch.save({\n",
        "  'epoch': epoch,\n",
        "  'model_state_dict': model.state_dict(),\n",
        "  'optimizer_state_dict': optim.state_dict()}, os.path.join(DATA_ROOT, 'checkpoint.pt'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524,
          "referenced_widgets": [
            "6059ea958c2d46c0afc8263077c3befb",
            "f2acd67539d34c29b2770d4505a81f56",
            "21e4f5c0bf514e0fa4419f9a458508b4",
            "b8300986f5214537a706adb561af2e01",
            "08b61375ee9e4591a77a41ac712e8a82",
            "30a776e3824e45f28ff331a6f0e3d780",
            "40fe493458724be5b3941baa8e77506e",
            "5423a84d021942cba84067f38ef85c1a",
            "d191d86581444391a99c3993d78600ff",
            "223610815b044137bdaff4a20f1bfd8d",
            "07c7749ad1ca40cb87f71edb7dba57b1",
            "d1f9083837d4403d8ddc0c592cd1d2b0",
            "eb2b2c3bb9df4573bb81526e55ee3ae7",
            "01e0a184fc6542a685aaaa4e6380eab1",
            "f944e457b33444a48cbe7c74707f82ea",
            "87cef7a1c53d4333aed19a8980f61e87",
            "0bf2fefac7114a9e84c09392c470e9ad",
            "28285d65416746bbb9369bba8b43cc1b",
            "e1839ce1ca0645d3abd4a855581bd4cb",
            "9631a3849f5741728e84a26bf962d628",
            "52d8706ec12047d5a90c048cc6d1b13c",
            "1daa332f4d6a467e9b6a1b1bb8b03430"
          ]
        },
        "id": "x0Mew77eVych",
        "outputId": "288b342c-7af0-4415-94d3-9c16475dbed4"
      },
      "id": "x0Mew77eVych",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 01:   0%|           |   0%"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6059ea958c2d46c0afc8263077c3befb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 — Loss 3.1996\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 02:   0%|           |   0%"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1f9083837d4403d8ddc0c592cd1d2b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 5.40 GiB. GPU 0 has a total capacity of 39.56 GiB of which 1.44 GiB is free. Process 20617 has 38.11 GiB memory in use. Of the allocated memory 11.91 GiB is allocated by PyTorch, and 25.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5485645edbd3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m       )\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m       \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 5.40 GiB. GPU 0 has a total capacity of 39.56 GiB of which 1.44 GiB is free. Process 20617 has 38.11 GiB memory in use. Of the allocated memory 11.91 GiB is allocated by PyTorch, and 25.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), os.path.join(DATA_ROOT, 'model.pt'))"
      ],
      "metadata": {
        "id": "v0EJmEk--84x"
      },
      "id": "v0EJmEk--84x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(os.path.join(DATA_ROOT, 'model.pt'), map_location=device))"
      ],
      "metadata": {
        "id": "9YzrgZn98bIv",
        "outputId": "bfebae5b-0022-4380-d6f8-284eb3cf319b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9YzrgZn98bIv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_midi(model, tokenizer, audio_path, diff, pos_abs, pos_rel, max_len=1300, device='cpu', temp = 1.0):\n",
        "  model.eval()\n",
        "\n",
        "  y, sr = librosa.load(audio_path, sr=44100)\n",
        "  stft = librosa.stft(y, n_fft=1024, hop_length=256)\n",
        "  log_stft = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
        "  x = torch.tensor(log_stft, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "  diff = torch.tensor([diff]).float().to(device)\n",
        "  pos_rel = torch.tensor([pos_rel]).float().to(device)\n",
        "  pos_abs = torch.tensor([pos_abs], dtype=torch.long).to(device)\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "    memory = model.encoder(x)\n",
        "\n",
        "  generated = [tokenizer.special_tokens[1]]\n",
        "  for _ in range(max_len):\n",
        "    if _ % 100 == 0:\n",
        "      print(_)\n",
        "    y_input = torch.tensor([tokenizer.vocab[t] for t in generated], dtype=torch.long).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "      logits = model.decoder(y_input, memory, diff, pos_abs, pos_rel)\n",
        "    next_logits = logits[:, -1, :]\n",
        "    probabilities = F.softmax(next_logits / temp, dim=-1)\n",
        "    next_id = torch.multinomial(probabilities, num_samples=1).squeeze(0).item()\n",
        "    next_token = [key for key, val in tokenizer.vocab.items() if val == next_id][0]\n",
        "    generated.append(next_token)\n",
        "    if next_id == tokenizer.special_tokens_ids[2]:\n",
        "      break\n",
        "\n",
        "  if generated[0] == tokenizer.special_tokens[1]:\n",
        "    generated = generated[1:]\n",
        "  if generated[-1] == tokenizer.special_tokens[2]:\n",
        "    generated = generated[:-1]\n",
        "  generated_seq = TokSequence(tokens=generated)\n",
        "  print(len(generated_seq))\n",
        "\n",
        "  tokens = tokenizer.decode([generated_seq])\n",
        "  return tokens\n"
      ],
      "metadata": {
        "id": "uLGzalFJ-4Rr"
      },
      "id": "uLGzalFJ-4Rr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = os.path.join(DATA_ROOT,\"song\", \"0_0.mp3\")\n",
        "\n",
        "\n",
        "tokens = generate_midi(model, tokenizer, path, 1.5, 40, 0.4, max_len=2000, device=device, temp=1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDAq8sK-BhXn",
        "outputId": "c17bd684-975b-445a-b98c-0a15d23276ca"
      },
      "id": "qDAq8sK-BhXn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens)\n",
        "\n",
        "tokens.dump_midi(os.path.join(DATA_ROOT, '1.mid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOahP0ajK-8h",
        "outputId": "cb374668-c8ae-446e-b9dc-6fc6d0f15e1c"
      },
      "id": "uOahP0ajK-8h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score(ttype=Tick, tpq=220, begin=0, end=13847, tracks=1, notes=101, time_sig=1, key_sig=0, markers=0)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6059ea958c2d46c0afc8263077c3befb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2acd67539d34c29b2770d4505a81f56",
              "IPY_MODEL_21e4f5c0bf514e0fa4419f9a458508b4",
              "IPY_MODEL_b8300986f5214537a706adb561af2e01"
            ],
            "layout": "IPY_MODEL_08b61375ee9e4591a77a41ac712e8a82"
          }
        },
        "f2acd67539d34c29b2770d4505a81f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30a776e3824e45f28ff331a6f0e3d780",
            "placeholder": "​",
            "style": "IPY_MODEL_40fe493458724be5b3941baa8e77506e",
            "value": "Epoch 01: 100%"
          }
        },
        "21e4f5c0bf514e0fa4419f9a458508b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5423a84d021942cba84067f38ef85c1a",
            "max": 234,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d191d86581444391a99c3993d78600ff",
            "value": 234
          }
        },
        "b8300986f5214537a706adb561af2e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_223610815b044137bdaff4a20f1bfd8d",
            "placeholder": "​",
            "style": "IPY_MODEL_07c7749ad1ca40cb87f71edb7dba57b1",
            "value": " | 100%"
          }
        },
        "08b61375ee9e4591a77a41ac712e8a82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "30a776e3824e45f28ff331a6f0e3d780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40fe493458724be5b3941baa8e77506e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5423a84d021942cba84067f38ef85c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d191d86581444391a99c3993d78600ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "223610815b044137bdaff4a20f1bfd8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07c7749ad1ca40cb87f71edb7dba57b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1f9083837d4403d8ddc0c592cd1d2b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb2b2c3bb9df4573bb81526e55ee3ae7",
              "IPY_MODEL_01e0a184fc6542a685aaaa4e6380eab1",
              "IPY_MODEL_f944e457b33444a48cbe7c74707f82ea"
            ],
            "layout": "IPY_MODEL_87cef7a1c53d4333aed19a8980f61e87"
          }
        },
        "eb2b2c3bb9df4573bb81526e55ee3ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bf2fefac7114a9e84c09392c470e9ad",
            "placeholder": "​",
            "style": "IPY_MODEL_28285d65416746bbb9369bba8b43cc1b",
            "value": "Epoch 02:  15%"
          }
        },
        "01e0a184fc6542a685aaaa4e6380eab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1839ce1ca0645d3abd4a855581bd4cb",
            "max": 234,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9631a3849f5741728e84a26bf962d628",
            "value": 34
          }
        },
        "f944e457b33444a48cbe7c74707f82ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52d8706ec12047d5a90c048cc6d1b13c",
            "placeholder": "​",
            "style": "IPY_MODEL_1daa332f4d6a467e9b6a1b1bb8b03430",
            "value": " |  15%"
          }
        },
        "87cef7a1c53d4333aed19a8980f61e87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf2fefac7114a9e84c09392c470e9ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28285d65416746bbb9369bba8b43cc1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1839ce1ca0645d3abd4a855581bd4cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9631a3849f5741728e84a26bf962d628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52d8706ec12047d5a90c048cc6d1b13c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1daa332f4d6a467e9b6a1b1bb8b03430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}