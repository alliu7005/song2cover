{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2195f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from yt_dlp import YoutubeDL\n",
    "import librosa\n",
    "from madmom.features.beats import DBNBeatTrackingProcessor, RNNBeatProcessor\n",
    "from madmom.features.downbeats import DBNDownBeatTrackingProcessor, RNNDownBeatProcessor\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "import openl3\n",
    "from madmom.features.chords import DeepChromaChordRecognitionProcessor, majmin_targets_to_chord_labels\n",
    "from madmom.evaluation.chords import encode as encode_chords, merge_chords, reduce_to_triads\n",
    "from madmom.audio.chroma import DeepChromaProcessor\n",
    "import csv\n",
    "import pretty_midi\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e78cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mp3(url, out_path=\"./%(title)s.%(ext)s\"):\n",
    "    ydl_opts = {\n",
    "        \"format\": \"bestaudio/best\",\n",
    "        \"outtmpl\": out_path,\n",
    "        \"ffmpeg_location\": r\"C:\\FFmpeg\\bin\",\n",
    "        \"postprocessors\": [{\n",
    "            \"key\": \"FFmpegExtractAudio\",\n",
    "            \"preferredcodec\": \"mp3\",\n",
    "                \"preferredquality\": \"192\",\n",
    "        }],\n",
    "        \"quiet\": False,\n",
    "        \"no_warnings\": True, \n",
    "    }\n",
    "\n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb4f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beats_and_downbeats(y, sr, tempo=0):\n",
    "\n",
    "    if tempo == 0:\n",
    "        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    #beat_tracker = BeatNet(1, mode=\"online\", inference_model=\"PF\", thread=False)\n",
    "    #beats_np = beat_tracker.process(y)\n",
    "    #print(beats_np)\n",
    "    print(tempo)\n",
    "    sf.write(\"test.wav\",y,sr)\n",
    "    act = RNNDownBeatProcessor()(\"test.wav\")\n",
    "\n",
    "    dbn = DBNDownBeatTrackingProcessor(beats_per_bar=4, fps=100, min_bpm = tempo * 0.8, max_bpm = tempo * 1.2)\n",
    "\n",
    "    downbeats = dbn(act)\n",
    "\n",
    "    \n",
    "    beats = np.array([time for time, beat in downbeats])\n",
    "    downbeats = np.array([time for time, beat in downbeats if beat == 1])\n",
    "    print(60/np.mean(np.diff(beats)))\n",
    "    os.remove(\"test.wav\")\n",
    "    #print(beats_fixed)\n",
    "    #return beats\n",
    "    return (beats, downbeats, act, tempo)\n",
    "\n",
    "def load(path):\n",
    "    return librosa.load(path)\n",
    "\n",
    "def get_clicks(beats, sr):\n",
    "    return librosa.clicks(times=beats, sr=sr)\n",
    "\n",
    "def overlay(y, clicks, sr, path):\n",
    "    sf.write(\"y.wav\", y, sr, subtype='PCM_16')\n",
    "    sf.write(\"clicks.wav\", clicks, sr, subtype='PCM_16')\n",
    "\n",
    "   \n",
    "    y_audio = AudioSegment.from_wav(\"y.wav\")\n",
    "    clicks_audio = AudioSegment.from_wav(\"clicks.wav\")\n",
    "    audio = y_audio.overlay(clicks_audio)\n",
    "\n",
    "    os.remove(\"y.wav\")\n",
    "    os.remove(\"clicks.wav\")\n",
    "\n",
    "\n",
    "    audio.export(path, format=\"wav\")\n",
    "\n",
    "def trim_silence(y):\n",
    "    y_t, index = librosa.effects.trim(y, top_db=40)\n",
    "    return y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20dc339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_chroma(pm, sr, hop_length):\n",
    "    chroma = pm.get_chroma(fs=sr / hop_length)\n",
    "    return librosa.util.normalize(chroma + 1e-6, axis=0)\n",
    "\n",
    "def audio_to_chroma(y, sr, hop_length):\n",
    "    C = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=hop_length)\n",
    "    return C\n",
    "    #return librosa.util.normalize(C, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b67423d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_midi_segment(pm: pretty_midi.PrettyMIDI, times):\n",
    "    t0, t1 = times\n",
    "    seg = pretty_midi.PrettyMIDI()\n",
    "    for instr in pm.instruments:\n",
    "        instr_seg = pretty_midi.Instrument(program=instr.program,\n",
    "                                           is_drum=instr.is_drum)\n",
    "        for note in instr.notes:\n",
    "            if note.start >= t0 and note.start < t1:\n",
    "                n = pretty_midi.Note(\n",
    "                    velocity=note.velocity,\n",
    "                    pitch=note.pitch,\n",
    "                    start=note.start - t0,\n",
    "                    end  =min(note.end - t0, t1 - t0)\n",
    "                )\n",
    "                instr_seg.notes.append(n)\n",
    "        seg.instruments.append(instr_seg)\n",
    "    return seg\n",
    "\n",
    "def concat_midi(midis):\n",
    "    merged = pretty_midi.PrettyMIDI()\n",
    "    merged.instruments = [instr for instr in midis[0].instruments]\n",
    "    current_time = midis[0].get_end_time()\n",
    "\n",
    "    # Iterate over the rest\n",
    "    for pm in midis[1:]:\n",
    "        # For each instrument in this segment\n",
    "        for instr in pm.instruments:\n",
    "            # Copy the instrument and shift its notes/events\n",
    "            instr_copy = pretty_midi.Instrument(\n",
    "                program=instr.program,\n",
    "                is_drum=instr.is_drum,\n",
    "                name=instr.name\n",
    "            )\n",
    "            # Shift each note\n",
    "            for note in instr.notes:\n",
    "                instr_copy.notes.append(pretty_midi.Note(\n",
    "                    velocity=note.velocity,\n",
    "                    pitch=note.pitch,\n",
    "                    start=note.start + current_time,\n",
    "                    end=note.end   + current_time\n",
    "                ))\n",
    "            # Shift any control changes or pitch bends if you care to preserve them:\n",
    "            for cc in instr.control_changes:\n",
    "                instr_copy.control_changes.append(pretty_midi.ControlChange(\n",
    "                    number=cc.number,\n",
    "                    value=cc.value,\n",
    "                    time=cc.time + current_time\n",
    "                ))\n",
    "            for pb in instr.pitch_bends:\n",
    "                instr_copy.pitch_bends.append(pretty_midi.PitchBend(\n",
    "                    pitch=pb.pitch,\n",
    "                    time=pb.time + current_time\n",
    "                ))\n",
    "            merged.instruments.append(instr_copy)\n",
    "\n",
    "        # Advance the time offset by this segmentâ€™s length\n",
    "        current_time += pm.get_end_time()\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "def dtw_align_m(y_s_harmonic, y_s, midi_p, downbeats_s, downbeats_p, sr, hop_length=512, n_beats=8, sim_metric='cosine', cost_threshold=1e3):\n",
    "    aligned = []\n",
    "    seg_s = []\n",
    "    seg_p = []\n",
    "    seg_p_list = []\n",
    "    i = 0\n",
    "    print(len(downbeats_s), len(downbeats_p))\n",
    "    while i < len(downbeats_s) or i < len(downbeats_p):\n",
    "        if i + n_beats >= min(len(downbeats_s), len(downbeats_p)) - 1:\n",
    "            break\n",
    "\n",
    "        t0_p, t1_p = downbeats_p[i], downbeats_p[i+n_beats]\n",
    "        t0_s, t1_s = downbeats_s[i], downbeats_s[i+n_beats]\n",
    "\n",
    "        mid_chunk_p = slice_midi_segment(midi_p, (t0_p, t1_p))\n",
    "        s0_s, s1_s = int(t0_s * sr), int(t1_s * sr)\n",
    "\n",
    "        y_chunk_s_harmonic = y_s_harmonic[s0_s: s1_s]\n",
    "        y_chunk_s = y_s[s0_s: s1_s]\n",
    "\n",
    "        C_s = audio_to_chroma(y_chunk_s_harmonic, sr, hop_length)\n",
    "        C_p = midi_to_chroma(mid_chunk_p, sr, hop_length)\n",
    "\n",
    "        D_feat = cdist(C_p.T, C_s.T, metric=sim_metric)\n",
    "\n",
    "        alpha = 0.03\n",
    "        idx1 = np.arange(D_feat.shape[0])[:,None]\n",
    "        idx2 = np.arange(D_feat.shape[1])[None,:]\n",
    "        D_time = alpha * np.abs(idx1 - idx2)\n",
    "\n",
    "        Cost = D_feat + D_time\n",
    "\n",
    "        D, wp = librosa.sequence.dtw(C=Cost)\n",
    "        cost = D[-1, -1]\n",
    "\n",
    "        print(i, cost)\n",
    "        if cost < cost_threshold:\n",
    "            aligned.append((t0_p, t1_p, t0_s, t1_s, cost))\n",
    "            seg_p.append(mid_chunk_p)\n",
    "            seg_s.append(y_chunk_s)\n",
    "            #j += 8\n",
    "            i += 8\n",
    "        else:\n",
    "            break\n",
    "            #if len(downbeats_p) < len(downbeats_s):\n",
    "            #    i += 1\n",
    "            #else:\n",
    "            #   j += 1\n",
    "\n",
    "    return aligned, seg_p, seg_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efdee4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=dIxAEusj2bk\n",
      "[youtube] dIxAEusj2bk: Downloading webpage\n",
      "[youtube] dIxAEusj2bk: Downloading tv client config\n",
      "[youtube] dIxAEusj2bk: Downloading tv player API JSON\n",
      "[youtube] dIxAEusj2bk: Downloading ios player API JSON\n",
      "[youtube] dIxAEusj2bk: Downloading m3u8 information\n",
      "[info] dIxAEusj2bk: Downloading 1 format(s): 251\n",
      "[download] Destination: song\\64\n",
      "[download] 100% of    3.26MiB in 00:00:00 at 4.20MiB/s   \n",
      "[ExtractAudio] Destination: song\\64.mp3\n",
      "Deleting original file song\\64 (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aymli\\anaconda3\\envs\\process\\lib\\site-packages\\pretty_midi\\pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.71234026389882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aymli\\anaconda3\\envs\\process\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123.040182743225\n",
      "99 103\n",
      "0 438.3889112795598\n",
      "8 477.2026475096992\n",
      "16 452.0804793983694\n",
      "24 371.28914963519105\n",
      "32 381.501618089245\n",
      "40 422.9468254690411\n",
      "48 430.3549184022059\n",
      "56 370.4823476356861\n",
      "64 367.28687130344053\n",
      "72 428.4311459699791\n",
      "80 366.2449873021282\n",
      "88 367.62923809010584\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=9WpBf2O7whw\n",
      "[youtube] 9WpBf2O7whw: Downloading webpage\n",
      "[youtube] 9WpBf2O7whw: Downloading tv client config\n",
      "[youtube] 9WpBf2O7whw: Downloading tv player API JSON\n",
      "[youtube] 9WpBf2O7whw: Downloading ios player API JSON\n",
      "[youtube] 9WpBf2O7whw: Downloading m3u8 information\n",
      "[info] 9WpBf2O7whw: Downloading 1 format(s): 251\n",
      "[download] Destination: song\\65\n",
      "[download] 100% of    2.93MiB in 00:00:03 at 929.27KiB/s   \n",
      "[ExtractAudio] Destination: song\\65.mp3\n",
      "Deleting original file song\\65 (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aymli\\anaconda3\\envs\\process\\lib\\site-packages\\pretty_midi\\pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117.99990166674812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aymli\\anaconda3\\envs\\process\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117.11446881062967\n",
      "83 82\n",
      "0 426.87802240894445\n",
      "8 400.3972000929896\n",
      "16 407.0377737867254\n",
      "24 349.1430805826463\n",
      "32 357.3305658812588\n",
      "40 363.4317856599559\n",
      "48 391.74250219959964\n",
      "56 338.72179614819686\n",
      "64 272.0463360989768\n",
      "72 381.39600010835716\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=M2M5Tm64swM\n",
      "[youtube] M2M5Tm64swM: Downloading webpage\n",
      "[youtube] M2M5Tm64swM: Downloading tv client config\n",
      "[youtube] M2M5Tm64swM: Downloading tv player API JSON\n",
      "[youtube] M2M5Tm64swM: Downloading ios player API JSON\n",
      "[youtube] M2M5Tm64swM: Downloading m3u8 information\n",
      "[info] M2M5Tm64swM: Downloading 1 format(s): 251\n",
      "[download] Destination: song\\66\n",
      "[download] 100% of    2.76MiB in 00:00:00 at 5.97MiB/s   \n",
      "[ExtractAudio] Destination: song\\66.mp3\n",
      "Deleting original file song\\66 (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aymli\\anaconda3\\envs\\process\\lib\\site-packages\\pretty_midi\\pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.99984166693015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aymli\\anaconda3\\envs\\process\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.98392673015103\n",
      "66 66\n",
      "0 399.37213677165624\n",
      "8 355.55311382126627\n",
      "16 413.68279518120215\n",
      "24 397.8657304114511\n",
      "32 334.4769167498529\n",
      "40 408.3734566678995\n",
      "48 337.2516983299544\n",
      "56 364.53677821327864\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=4Pe20y_-32c\n",
      "[youtube] 4Pe20y_-32c: Downloading webpage\n",
      "[youtube] 4Pe20y_-32c: Downloading tv client config\n",
      "[youtube] 4Pe20y_-32c: Downloading tv player API JSON\n",
      "[youtube] 4Pe20y_-32c: Downloading ios player API JSON\n",
      "[youtube] 4Pe20y_-32c: Downloading m3u8 information\n",
      "[info] 4Pe20y_-32c: Downloading 1 format(s): 251\n",
      "[download] Destination: song\\67\n",
      "[download] 100% of    3.48MiB in 00:00:01 at 2.74MiB/s   \n",
      "[ExtractAudio] Destination: song\\67.mp3\n",
      "Deleting original file song\\67 (pass -k to keep)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'midi/67.mid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m y_s_harmonic, y_s_percussive \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39meffects\u001b[38;5;241m.\u001b[39mhpss(y_s)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#y_p_harmonic, y_p_percussive = librosa.effects.hpss(y_p)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m pm \u001b[38;5;241m=\u001b[39m \u001b[43mpretty_midi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPrettyMIDI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmidi/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m C_s \u001b[38;5;241m=\u001b[39m audio_to_chroma(y_s_harmonic, sr, hop_length)\n\u001b[0;32m     21\u001b[0m C_p \u001b[38;5;241m=\u001b[39m midi_to_chroma(pm, sr, hop_length)\n",
      "File \u001b[1;32mc:\\Users\\aymli\\anaconda3\\envs\\process\\lib\\site-packages\\pretty_midi\\pretty_midi.py:63\u001b[0m, in \u001b[0;36mPrettyMIDI.__init__\u001b[1;34m(self, midi_file, resolution, initial_tempo)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m midi_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# Load in the MIDI data using the midi module\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(midi_file, six\u001b[38;5;241m.\u001b[39mstring_types):\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;66;03m# If a string was given, pass it as the string filename\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m         midi_data \u001b[38;5;241m=\u001b[39m \u001b[43mmido\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMidiFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmidi_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;66;03m# Otherwise, try passing it in as a file pointer\u001b[39;00m\n\u001b[0;32m     66\u001b[0m         midi_data \u001b[38;5;241m=\u001b[39m mido\u001b[38;5;241m.\u001b[39mMidiFile(file\u001b[38;5;241m=\u001b[39mmidi_file)\n",
      "File \u001b[1;32mc:\\Users\\aymli\\anaconda3\\envs\\process\\lib\\site-packages\\mido\\midifiles\\midifiles.py:319\u001b[0m, in \u001b[0;36mMidiFile.__init__\u001b[1;34m(self, filename, file, type, ticks_per_beat, charset, debug, clip, tracks)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load(file)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 319\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load(file)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'midi/67.mid'"
     ]
    }
   ],
   "source": [
    "song_links = []\n",
    "hop_length = 512\n",
    "with open(\"links.csv\", newline=\"\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        song_links.append(row[\"audio_link\"])\n",
    "\n",
    "for i in range(len(song_links)):\n",
    "    if i > 63:\n",
    "        download_mp3(song_links[i], f\"song/{i}\")\n",
    "\n",
    "        y_s, sr = librosa.load(f\"song/{i}.mp3\")\n",
    "        y_s = trim_silence(y_s)\n",
    "\n",
    "        y_s_harmonic, y_s_percussive = librosa.effects.hpss(y_s)\n",
    "            #y_p_harmonic, y_p_percussive = librosa.effects.hpss(y_p)\n",
    "\n",
    "        pm = pretty_midi.PrettyMIDI(f\"midi/{i}.mid\")\n",
    "\n",
    "        C_s = audio_to_chroma(y_s_harmonic, sr, hop_length)\n",
    "        C_p = midi_to_chroma(pm, sr, hop_length)\n",
    "\n",
    "        \n",
    "        downbeats_p = pm.get_downbeats()\n",
    "        beats_p = pm.get_beats()\n",
    "\n",
    "        tempo_p = 60 / np.mean(np.diff(beats_p))\n",
    "\n",
    "        beats_s, downbeats_s, act_s, tempo_s = get_beats_and_downbeats(y_s, sr, tempo=tempo_p)\n",
    "\n",
    "        if tempo_p / 1.8 > tempo_s:\n",
    "            beats_s, downbeats_s, act_s, tempo_s = get_beats_and_downbeats(y_s, sr, tempo=tempo_p)\n",
    "\n",
    "        if tempo_s / 1.8 > tempo_p:\n",
    "            beats_s, downbeats_s, act_s, tempo_s = get_beats_and_downbeats(y_s, sr, tempo=tempo_p)\n",
    "\n",
    "\n",
    "        aligned, pm_list, y_s_list = dtw_align_m(y_s_harmonic, y_s, pm, downbeats_s, downbeats_p, sr, hop_length=512, n_beats=8, sim_metric='cosine', cost_threshold=500)\n",
    "\n",
    "        os.remove(f\"song/{i}.mp3\")\n",
    "\n",
    "        if len(y_s_list) != 0:\n",
    "            for j in range(len(y_s_list)):\n",
    "                pm_list[j].write(f\"midi_done/{i}_{j}.mid\")\n",
    "                sf.write(f\"song/{i}_{j}.mp3\",  y_s_list[j], sr, bitrate_mode='VARIABLE', compression_level=0)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "process",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
